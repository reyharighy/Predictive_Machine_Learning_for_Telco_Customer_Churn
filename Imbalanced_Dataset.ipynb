{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importing Related Notebooks** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import Model_Benchmarking\n",
    "\n",
    "gb = Model_Benchmarking.gb\n",
    "X_trainval = Model_Benchmarking.X_trainval\n",
    "y_trainval = Model_Benchmarking.y_trainval\n",
    "X_test = Model_Benchmarking.X_test\n",
    "y_test = Model_Benchmarking.y_test\n",
    "skfold = Model_Benchmarking.skfold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Imbalanced Dataset**\n",
    "\n",
    "As previously known, the dataset as a whole has an unequal proportion of target classes where in this case study, the number of customers who churn is far less than subscribers who are still subscribed. This can cause several disadvantages, including model performance that tends to be biased, poor generalization, non-representative measurement evaluation results, and wrong interpretation of existing problems. This happens because the amount of data for the minority class, in this case churn customers, is insufficient when the training process is carried out on the algorithm model used. As a result, the algorithm model will produce poor performance in detecting churn customers even though overall it has fairly good accuracy. These deficiencies can be anticipated by manipulating the data so that the number of positive and negative classes is equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Imbalanced Cross Validation Score**\n",
    "\n",
    "The strategy that can be done is to use several class that are already available by **imblearn**, including `RandomOverSampler()`, `SMOTE()`, `RandomUnderSampler()`, and ` NearMiss()`. Each class has its own advantages and disadvantages in handling imbalanced data cases so a cross validation score process will be carried out to find the average performance of each class against the dataset used for the training process and validation, namely `X_trainval` and `y_trainval`. Then, a testing process will be carried out on dataset `X_test` and `y_test`.\n",
    "\n",
    "This will be easier by creating an artificial class that is capable of carrying out the process. This class consists of three methods which have their respective designations, namely `imbalance_validation()`, `imbalance_test_score()`, and `imbalance_classification_report()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from sklearn.metrics import fbeta_score, average_precision_score, precision_score, recall_score, classification_report\n",
    "\n",
    "class imbalance_val_score:\n",
    "    def __init__(self,estimator):\n",
    "        self.estimator = estimator\n",
    "        self.methods = ['1','2','3','4','5']\n",
    "    \n",
    "    def imbalance_validation(self,X_trainval,y_trainval):\n",
    "        ap_scores, f2_scores, pr_scores, re_scores = [], [], [], []\n",
    "        result_scores = [ap_scores, f2_scores, pr_scores, re_scores]\n",
    "        \n",
    "        for method in self.methods:\n",
    "            ap_method, f2_method, pr_method, re_method = [], [], [], []\n",
    "            method_scores = [ap_method, f2_method, pr_method, re_method]\n",
    "            \n",
    "            for train, validation in skfold.split(X_trainval,y_trainval):\n",
    "                X_train = X_trainval.iloc[train]\n",
    "                y_train = y_trainval.iloc[train]\n",
    "                X_val = X_trainval.iloc[validation]\n",
    "                y_val = y_trainval.iloc[validation]\n",
    "                scores = (self.method(\n",
    "                    estimator=self.estimator,\n",
    "                    X_train=X_train,\n",
    "                    y_train=y_train,\n",
    "                    X_test=X_val,\n",
    "                    y_test=y_val,\n",
    "                    method=method\n",
    "                ).method_score())\n",
    "                \n",
    "                for i in zip(method_scores,scores):\n",
    "                    i[0].append(i[1])\n",
    "            \n",
    "            for i in zip(result_scores,method_scores):\n",
    "                i[0].append(i[1])\n",
    "        \n",
    "        return ap_scores, f2_scores, pr_scores, re_scores\n",
    "    \n",
    "    def imbalance_test_score(self,X_trainval,y_trainval,X_test,y_test):\n",
    "        ap_scores, f2_scores, pr_scores, re_scores = [], [], [], []\n",
    "        result_scores = [ap_scores, f2_scores, pr_scores, re_scores]\n",
    "        \n",
    "        for method in self.methods:\n",
    "            scores = (self.method(\n",
    "                estimator=self.estimator,\n",
    "                X_train=X_trainval,\n",
    "                y_train=y_trainval,\n",
    "                X_test=X_test,\n",
    "                y_test=y_test,\n",
    "                method=method\n",
    "            ).method_score())\n",
    "            \n",
    "            for i in zip(result_scores,scores):\n",
    "                i[0].append(i[1])\n",
    "        \n",
    "        return ap_scores, f2_scores, pr_scores, re_scores\n",
    "    \n",
    "    def imbalance_classification_report(self,X_trainval,y_trainval,X_test,y_test):\n",
    "        reports = []\n",
    "\n",
    "        for method in self.methods:\n",
    "            reports.append(self.method(\n",
    "                estimator=self.estimator,\n",
    "                X_train=X_trainval,\n",
    "                y_train=y_trainval,\n",
    "                X_test=X_test,\n",
    "                y_test=y_test,\n",
    "                method=method\n",
    "            ).method_report())\n",
    "        \n",
    "        return reports\n",
    "\n",
    "    class method:\n",
    "        def __init__(self,estimator,X_train,y_train,X_test,y_test,method):\n",
    "            self.X_train = X_train\n",
    "            self.y_train = y_train\n",
    "            self.X_test = X_test\n",
    "            self.y_test = y_test\n",
    "            self.estimator = estimator \n",
    "            self.method = method\n",
    "\n",
    "        def method_score(self):\n",
    "            X_resampled, y_resampled = self.selection(\n",
    "                X_train=self.X_train,\n",
    "                y_train=self.y_train,\n",
    "                method=self.method\n",
    "            ).get_samples()\n",
    "\n",
    "            scores = (self.calculate(\n",
    "                estimator=self.estimator,\n",
    "                X_train=X_resampled,\n",
    "                y_train=y_resampled\n",
    "            ).get_results(\n",
    "                X_test=X_test,\n",
    "                y_test=y_test\n",
    "            ))\n",
    "\n",
    "            return scores\n",
    "        \n",
    "        def method_report(self):\n",
    "            X_resampled, y_resampled = self.selection(\n",
    "                X_train=self.X_train,\n",
    "                y_train=self.y_train,\n",
    "                method=self.method\n",
    "            ).get_samples()\n",
    "\n",
    "            report = self.calculate(\n",
    "                estimator=self.estimator,\n",
    "                X_train=X_resampled,\n",
    "                y_train=y_resampled\n",
    "            ).get_report(\n",
    "                X_test=X_test,\n",
    "                y_test=y_test\n",
    "            )\n",
    "\n",
    "            return report\n",
    "\n",
    "        class selection:\n",
    "            def __init__(self,X_train,y_train,method):\n",
    "                self.X_train = X_train\n",
    "                self.y_train = y_train\n",
    "                self.method = method\n",
    "\n",
    "            def get_samples(self):\n",
    "                if self.method in ['1','2','3']:\n",
    "                    method_dict = {\n",
    "                        '1':RandomOverSampler,\n",
    "                        '2':RandomUnderSampler,\n",
    "                        '3':SMOTE\n",
    "                    }\n",
    "\n",
    "                    X_resampled, y_resampled = method_dict.setdefault(self.method)\\\n",
    "                        (random_state=1995).fit_resample(\n",
    "                              X=self.X_train, \n",
    "                              y=self.y_train\n",
    "                        )\n",
    "\n",
    "                elif self.method == '4':\n",
    "                    X_resampled, y_resampled = NearMiss().fit_resample(\n",
    "                        X=self.X_train,\n",
    "                        y=self.y_train\n",
    "                    )\n",
    "\n",
    "                else:\n",
    "                    X_resampled = self.X_train\n",
    "                    y_resampled = self.y_train\n",
    "\n",
    "                return X_resampled, y_resampled\n",
    "\n",
    "        class calculate:\n",
    "            def __init__(self,estimator,X_train,y_train):\n",
    "                self.estimator = estimator.fit(\n",
    "                    X=X_train,\n",
    "                    y=y_train\n",
    "                )\n",
    "            \n",
    "            def get_results(self,X_test,y_test):\n",
    "                ap_score = average_precision_score(\n",
    "                    y_true=y_test,\n",
    "                    y_score=self.estimator.predict_proba(X_test)[:,1]\n",
    "                )\n",
    "\n",
    "                f2_score = fbeta_score(\n",
    "                    y_true=y_test,\n",
    "                    y_pred=self.estimator.predict(X_test),\n",
    "                    beta=2\n",
    "                )\n",
    "\n",
    "                pr_score = precision_score(\n",
    "                    y_true=y_test,\n",
    "                    y_pred=self.estimator.predict(X_test)\n",
    "                )\n",
    "                re_score = recall_score(\n",
    "                    y_true=y_test,\n",
    "                    y_pred=self.estimator.predict(X_test)\n",
    "                )\n",
    "                                    \n",
    "                return [ap_score,f2_score,pr_score,re_score]\n",
    "            \n",
    "            def get_report(self,X_test,y_test):\n",
    "                return classification_report(\n",
    "                    y_true=y_test,\n",
    "                    y_pred=self.estimator.predict(X_test)\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we will process cross validation score using method `imbalance_validation()` and display it in dataframe using training and validation data from `X_trainval` and `y_trainval`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Fold 1</th>\n",
       "      <th>Fold 2</th>\n",
       "      <th>Fold 3</th>\n",
       "      <th>Fold 4</th>\n",
       "      <th>Fold 5</th>\n",
       "      <th>Average</th>\n",
       "      <th>STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Over Sampling</th>\n",
       "      <th>AP Score</th>\n",
       "      <td>68.14</td>\n",
       "      <td>69.45</td>\n",
       "      <td>69.29</td>\n",
       "      <td>68.79</td>\n",
       "      <td>68.85</td>\n",
       "      <td>68.90</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2 Score</th>\n",
       "      <td>74.96</td>\n",
       "      <td>75.94</td>\n",
       "      <td>76.92</td>\n",
       "      <td>76.80</td>\n",
       "      <td>74.41</td>\n",
       "      <td>75.81</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>55.15</td>\n",
       "      <td>55.39</td>\n",
       "      <td>55.62</td>\n",
       "      <td>53.82</td>\n",
       "      <td>53.69</td>\n",
       "      <td>54.73</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>82.35</td>\n",
       "      <td>83.71</td>\n",
       "      <td>85.07</td>\n",
       "      <td>85.97</td>\n",
       "      <td>82.35</td>\n",
       "      <td>83.89</td>\n",
       "      <td>1.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Under Sampling</th>\n",
       "      <th>AP Score</th>\n",
       "      <td>66.70</td>\n",
       "      <td>68.75</td>\n",
       "      <td>66.51</td>\n",
       "      <td>67.94</td>\n",
       "      <td>65.59</td>\n",
       "      <td>67.10</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2 Score</th>\n",
       "      <td>75.34</td>\n",
       "      <td>76.12</td>\n",
       "      <td>75.22</td>\n",
       "      <td>75.32</td>\n",
       "      <td>75.71</td>\n",
       "      <td>75.54</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>52.38</td>\n",
       "      <td>52.20</td>\n",
       "      <td>52.09</td>\n",
       "      <td>51.65</td>\n",
       "      <td>53.28</td>\n",
       "      <td>52.32</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>84.62</td>\n",
       "      <td>85.97</td>\n",
       "      <td>84.62</td>\n",
       "      <td>85.07</td>\n",
       "      <td>84.62</td>\n",
       "      <td>84.98</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">SMOTE</th>\n",
       "      <th>AP Score</th>\n",
       "      <td>67.60</td>\n",
       "      <td>69.56</td>\n",
       "      <td>69.52</td>\n",
       "      <td>69.17</td>\n",
       "      <td>70.59</td>\n",
       "      <td>69.29</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2 Score</th>\n",
       "      <td>72.15</td>\n",
       "      <td>73.15</td>\n",
       "      <td>71.90</td>\n",
       "      <td>72.68</td>\n",
       "      <td>74.00</td>\n",
       "      <td>72.78</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>55.84</td>\n",
       "      <td>55.17</td>\n",
       "      <td>54.23</td>\n",
       "      <td>55.59</td>\n",
       "      <td>56.73</td>\n",
       "      <td>55.51</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>77.83</td>\n",
       "      <td>79.64</td>\n",
       "      <td>78.28</td>\n",
       "      <td>78.73</td>\n",
       "      <td>80.09</td>\n",
       "      <td>78.91</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Near Miss</th>\n",
       "      <th>AP Score</th>\n",
       "      <td>28.66</td>\n",
       "      <td>21.66</td>\n",
       "      <td>35.49</td>\n",
       "      <td>24.23</td>\n",
       "      <td>26.97</td>\n",
       "      <td>27.40</td>\n",
       "      <td>4.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2 Score</th>\n",
       "      <td>60.29</td>\n",
       "      <td>55.29</td>\n",
       "      <td>61.09</td>\n",
       "      <td>57.27</td>\n",
       "      <td>57.76</td>\n",
       "      <td>58.34</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>33.33</td>\n",
       "      <td>28.15</td>\n",
       "      <td>39.15</td>\n",
       "      <td>30.24</td>\n",
       "      <td>33.05</td>\n",
       "      <td>32.79</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>75.57</td>\n",
       "      <td>72.85</td>\n",
       "      <td>71.04</td>\n",
       "      <td>73.76</td>\n",
       "      <td>71.04</td>\n",
       "      <td>72.85</td>\n",
       "      <td>1.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Normal Sampling</th>\n",
       "      <th>AP Score</th>\n",
       "      <td>69.01</td>\n",
       "      <td>69.23</td>\n",
       "      <td>69.53</td>\n",
       "      <td>68.81</td>\n",
       "      <td>70.11</td>\n",
       "      <td>69.34</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2 Score</th>\n",
       "      <td>62.21</td>\n",
       "      <td>61.04</td>\n",
       "      <td>61.52</td>\n",
       "      <td>58.77</td>\n",
       "      <td>60.28</td>\n",
       "      <td>60.76</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>67.16</td>\n",
       "      <td>69.31</td>\n",
       "      <td>67.51</td>\n",
       "      <td>67.02</td>\n",
       "      <td>69.35</td>\n",
       "      <td>68.07</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>61.09</td>\n",
       "      <td>59.28</td>\n",
       "      <td>60.18</td>\n",
       "      <td>57.01</td>\n",
       "      <td>58.37</td>\n",
       "      <td>59.19</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Average  \\\n",
       "Over Sampling   AP Score    68.14   69.45   69.29   68.79   68.85    68.90   \n",
       "                F2 Score    74.96   75.94   76.92   76.80   74.41    75.81   \n",
       "                Precision   55.15   55.39   55.62   53.82   53.69    54.73   \n",
       "                Recall      82.35   83.71   85.07   85.97   82.35    83.89   \n",
       "Under Sampling  AP Score    66.70   68.75   66.51   67.94   65.59    67.10   \n",
       "                F2 Score    75.34   76.12   75.22   75.32   75.71    75.54   \n",
       "                Precision   52.38   52.20   52.09   51.65   53.28    52.32   \n",
       "                Recall      84.62   85.97   84.62   85.07   84.62    84.98   \n",
       "SMOTE           AP Score    67.60   69.56   69.52   69.17   70.59    69.29   \n",
       "                F2 Score    72.15   73.15   71.90   72.68   74.00    72.78   \n",
       "                Precision   55.84   55.17   54.23   55.59   56.73    55.51   \n",
       "                Recall      77.83   79.64   78.28   78.73   80.09    78.91   \n",
       "Near Miss       AP Score    28.66   21.66   35.49   24.23   26.97    27.40   \n",
       "                F2 Score    60.29   55.29   61.09   57.27   57.76    58.34   \n",
       "                Precision   33.33   28.15   39.15   30.24   33.05    32.79   \n",
       "                Recall      75.57   72.85   71.04   73.76   71.04    72.85   \n",
       "Normal Sampling AP Score    69.01   69.23   69.53   68.81   70.11    69.34   \n",
       "                F2 Score    62.21   61.04   61.52   58.77   60.28    60.76   \n",
       "                Precision   67.16   69.31   67.51   67.02   69.35    68.07   \n",
       "                Recall      61.09   59.28   60.18   57.01   58.37    59.19   \n",
       "\n",
       "                            STD  \n",
       "Over Sampling   AP Score   0.46  \n",
       "                F2 Score   0.99  \n",
       "                Precision  0.81  \n",
       "                Recall     1.45  \n",
       "Under Sampling  AP Score   1.11  \n",
       "                F2 Score   0.33  \n",
       "                Precision  0.54  \n",
       "                Recall     0.53  \n",
       "SMOTE           AP Score   0.97  \n",
       "                F2 Score   0.75  \n",
       "                Precision  0.82  \n",
       "                Recall     0.84  \n",
       "Near Miss       AP Score   4.70  \n",
       "                F2 Score   2.10  \n",
       "                Precision  3.71  \n",
       "                Recall     1.72  \n",
       "Normal Sampling AP Score   0.45  \n",
       "                F2 Score   1.18  \n",
       "                Precision  1.04  \n",
       "                Recall     1.41  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "estimator = gb\n",
    "sampling_score = imbalance_val_score(estimator).imbalance_validation(\n",
    "    X_trainval=X_trainval,\n",
    "    y_trainval=y_trainval\n",
    ")\n",
    "\n",
    "ap_scores, f2_scores, pr_scores, re_scores = [], [], [], []\n",
    "\n",
    "for i,var in enumerate([ap_scores,f2_scores,pr_scores,re_scores]):\n",
    "    for val in sampling_score[i]:\n",
    "        var.append(val)\n",
    "\n",
    "sampling_comparison = pd.DataFrame(data={\n",
    "    ('Over Sampling','AP Score'):ap_scores[0],\n",
    "    ('Over Sampling','F2 Score'):f2_scores[0],\n",
    "    ('Over Sampling','Precision'):pr_scores[0],\n",
    "    ('Over Sampling','Recall'):re_scores[0],\n",
    "    ('Under Sampling','AP Score'):ap_scores[1],\n",
    "    ('Under Sampling','F2 Score'):f2_scores[1],\n",
    "    ('Under Sampling','Precision'):pr_scores[1],\n",
    "    ('Under Sampling','Recall'):re_scores[1],\n",
    "    ('SMOTE','AP Score'):ap_scores[2],\n",
    "    ('SMOTE','F2 Score'):f2_scores[2],\n",
    "    ('SMOTE','Precision'):pr_scores[2],\n",
    "    ('SMOTE','Recall'):re_scores[2],\n",
    "    ('Near Miss','AP Score'):ap_scores[3],\n",
    "    ('Near Miss','F2 Score'):f2_scores[3],\n",
    "    ('Near Miss','Precision'):pr_scores[3],\n",
    "    ('Near Miss','Recall'):re_scores[3],\n",
    "    ('Normal Sampling','AP Score'):ap_scores[4],\n",
    "    ('Normal Sampling','F2 Score'):f2_scores[4],\n",
    "    ('Normal Sampling','Precision'):pr_scores[4],\n",
    "    ('Normal Sampling','Recall'):re_scores[4]\n",
    "})\n",
    "\n",
    "for function in [lambda x: x.mean(),lambda x: x.std()]:\n",
    "    sampling_comparison = sampling_comparison.append(\n",
    "        sampling_comparison.apply(\n",
    "            func=function,\n",
    "            axis=0\n",
    "        ),\n",
    "        ignore_index=True\n",
    "    )\n",
    "    \n",
    "sampling_comparison = sampling_comparison.rename(index={\n",
    "    0:'Fold 1',\n",
    "    1:'Fold 2',\n",
    "    2:'Fold 3',\n",
    "    3:'Fold 4',\n",
    "    4:'Fold 5',\n",
    "    5:'Average',\n",
    "    6:'STD'\n",
    "})\n",
    "\n",
    "sampling_comparison.apply(\n",
    "    func=lambda x: round(\n",
    "        number=x*100,\n",
    "        ndigits=2\n",
    "    )\n",
    ").transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the resampling method using SMOTE, over sampling, and under sampling has an Average Precision average result that is relatively equally good, with the best level of stability owned by `RandomOverSampling()` while the NearMiss produced the worst performance. On the other hand, based on the F2 Score measurement results, the over sampling and under sampling methods produce relatively equally good performance. For normal sampling, the Average Precision is quite good but has a much worse F2 Score because there is no resampling process to balance the amount of data for each target class.\n",
    "\n",
    "F2 Score measurement can be used as an additional reference in assessing the performance of a resampling method in which metrics combine precision and recall values ​​with more emphasis on recall values. In the case of this study, the recall value indicates how many actual occurrences of churn customers can be predicted by the algorithm model. Therefore, it is very useful when the losses incurred due to false negatives or failure to predict cases of churn customers are relatively greater than the losses incurred from false positives or wrong predictions of churn customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Imbalanced Testing**\n",
    "\n",
    "Next, a testing process will be carried out using data test for all resampling methods tested. This can be done using method `imbalance_test_score()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AP Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Over Sampling</th>\n",
       "      <td>68.03</td>\n",
       "      <td>74.88</td>\n",
       "      <td>54.14</td>\n",
       "      <td>82.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Under Sampling</th>\n",
       "      <td>68.22</td>\n",
       "      <td>74.96</td>\n",
       "      <td>52.86</td>\n",
       "      <td>83.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTE</th>\n",
       "      <td>69.90</td>\n",
       "      <td>72.56</td>\n",
       "      <td>55.24</td>\n",
       "      <td>78.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Near Miss</th>\n",
       "      <td>27.70</td>\n",
       "      <td>58.80</td>\n",
       "      <td>33.20</td>\n",
       "      <td>72.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normal Sampling</th>\n",
       "      <td>69.44</td>\n",
       "      <td>60.59</td>\n",
       "      <td>66.50</td>\n",
       "      <td>59.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AP Score  F2 Score  Precision  Recall\n",
       "Over Sampling       68.03     74.88      54.14   82.81\n",
       "Under Sampling      68.22     74.96      52.86   83.71\n",
       "SMOTE               69.90     72.56      55.24   78.73\n",
       "Near Miss           27.70     58.80      33.20   72.85\n",
       "Normal Sampling     69.44     60.59      66.50   59.28"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_score = imbalance_val_score(estimator).imbalance_test_score(\n",
    "    X_trainval=X_trainval,\n",
    "    y_trainval=y_trainval,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test\n",
    ")\n",
    "\n",
    "testing_comparison = pd.DataFrame(testing_score).apply(\n",
    "    func=lambda x: round(\n",
    "        number=x*100,\n",
    "        ndigits=2\n",
    "    )\n",
    ").transpose()\n",
    "\n",
    "testing_comparison.rename(\n",
    "    index={\n",
    "        0:'Over Sampling',\n",
    "        1:'Under Sampling',\n",
    "        2:'SMOTE',\n",
    "        3:'Near Miss',\n",
    "        4:'Normal Sampling'\n",
    "    },\n",
    "    columns={\n",
    "        0:'AP Score',\n",
    "        1:'F2 Score',\n",
    "        2:'Precision',\n",
    "        3:'Recall'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that SMOTE method is able to outperform other methods in terms of Average Precision measurement but has no better performance in terms of F2 Score measurement. This is similar to the results of the previous cross validation score. On the other hand, the over sampling and under sampling methods have relatively the same performance in terms of Average Precision and F2 Score. However, based on the results of the cross validation score, the over sampling method has a better level of stability in predicting the probability of each possible recall value even though in the testing process the scores are not better than the SMOTE and under sampling. Based on overall performance, the over sampling method will be used in the process of developing the necessary algorithm model according to the existing business problem.\n",
    "\n",
    "Next, a classification report for each resampling method will be displayed as additional information using method `imbalance_classification_report()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================Over Sampling===================== \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.79      0.85       723\n",
      "           1       0.54      0.83      0.65       221\n",
      "\n",
      "    accuracy                           0.80       944\n",
      "   macro avg       0.74      0.81      0.75       944\n",
      "weighted avg       0.84      0.80      0.81       944\n",
      "\n",
      "======================================================= \n",
      "\n",
      "=====================Under Sampling==================== \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.77      0.85       723\n",
      "           1       0.53      0.84      0.65       221\n",
      "\n",
      "    accuracy                           0.79       944\n",
      "   macro avg       0.73      0.80      0.75       944\n",
      "weighted avg       0.84      0.79      0.80       944\n",
      "\n",
      "======================================================= \n",
      "\n",
      "=========================SMOTE========================= \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.80      0.86       723\n",
      "           1       0.55      0.79      0.65       221\n",
      "\n",
      "    accuracy                           0.80       944\n",
      "   macro avg       0.74      0.80      0.76       944\n",
      "weighted avg       0.84      0.80      0.81       944\n",
      "\n",
      "======================================================= \n",
      "\n",
      "=======================Near Miss======================= \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.55      0.68       723\n",
      "           1       0.33      0.73      0.46       221\n",
      "\n",
      "    accuracy                           0.59       944\n",
      "   macro avg       0.60      0.64      0.57       944\n",
      "weighted avg       0.74      0.59      0.62       944\n",
      "\n",
      "======================================================= \n",
      "\n",
      "====================Normal Sampling==================== \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       723\n",
      "           1       0.66      0.59      0.63       221\n",
      "\n",
      "    accuracy                           0.83       944\n",
      "   macro avg       0.77      0.75      0.76       944\n",
      "weighted avg       0.83      0.83      0.83       944\n",
      "\n",
      "======================================================= \n",
      "\n"
     ]
    }
   ],
   "source": [
    "reports = imbalance_val_score(estimator).imbalance_classification_report(\n",
    "    X_trainval=X_trainval,\n",
    "    y_trainval=y_trainval,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test\n",
    ")\n",
    "\n",
    "for report,j in zip(reports,['Over Sampling','Under Sampling','SMOTE','Near Miss','Normal Sampling']):\n",
    "    print(\n",
    "        j.center(55,'='),\n",
    "        '\\n\\n'+report+'\\n'+('=').center(55,'='),\n",
    "        '\\n'\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
